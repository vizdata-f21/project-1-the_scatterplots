---
title: Quality of U.S. Public Parks
author: The Scatterplots
output: github_document
---

```{r load-packages, echo = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(jsonlite)
library(scales)
library(maps)

#install.packages("cowplot")  # a gganimate dependency
#devtools::install_github('thomasp85/gganimate')
#remotes::install_github("thomasp85/gganimate@v0.1.1")

library(gganimate)

install.packages("gifski")
library(gifski)
library(png)

#Figure Sizing
knitr::opts_chunk$set(fig.width = 10,
                      fig.asp = 0.618,
                      out.width = "90%")
```

```{r load-data, echo = FALSE}
parks <- read.csv("~/R/project-1-the_scatterplots/data/parks.csv")
#parks <- read.csv("~/R/STA313/Projects/project-1-the_scatterplots/data/parks.csv")
cities <- fromJSON("~/R/project-1-the_scatterplots/data/cities.json")
#cities <- fromJSON("~/R/STA313/Projects/project-1-the_scatterplots/data/cities.json")
```

### Introduction

Our dataset comes from The Trust for Public Land’s ParkScore Index, an annually
released report which ranks the parks of the 100 most populated cities in the
United States according to 4 key metrics: access, investment, amenities, and
acreage. There are `r nrow(parks)` rows and `r ncol(parks)` columns in the data
set ranging from 2012 through 2020.

The COVID-19 Pandemic has laid bare a multitude of inequities that exist in the
United States. While many people were able to flock to their local parks in 
order to get out of the house, many others were not. Our group is interested in
exploring the Parks Access dataset in order to answer questions regarding access
and equity to the nation’s largest cities’ parks. The Citylab article
accompanying the dataset from TidyTuesday discussed a number of reasons for
unequal access to quality parks and we are hoping to explore these in our project.

## What is the relationship between spending per resident and park size in different U.S. regions and/or cities over time?

### Introduction

To answer our first question, we used the `parks` dataset and analyzed the 
relationship between the variables `spend_per_resident_data`, `city`, 
`med_park_size`, and `year`. We thought it would be interesting to look 
into how city budgets have allocated money for spending on their public parks and 
how this has varied across different US cities over the course of nearly the 
last decade. We also wanted to analyze how spending per resident and park size 
varies across different U.S regions and cities. We wanted to explore the 
relationship between these variables in light of the COVID-19 pandemic, where 
people across the US flocked to their local public parks. Namely, we wanted to 
see if the relationship was one we would expect- where the more money spent on 
parks per capita, the higher the median park size would be. 

### Approach
In order to ensure the final visualization had entries the variables of interest for all years between 
2012 and 2020, we did some data wrangling first and removed all cities which had
NAs for spend_per_resident_data, city, and med_park_size_data. 
This left us with a data frame with 4 columns: spend_per_resident_data, 
`city`, `med_park_size_data`, and `year`. At this point, all that was 
left to do was bin the data into quartiles for spending and for median park size. 
In order to bin the data appropriately, we used the fivenum command to find the 
quartiles in our data. This allowed us to analyze how spending trends shifted 
between 2012 and 2020 for each quartile, as well as visualize whether higher 
per capita spending resulted in larger median park size. While we initially felt 
that a line graph would be appropriate for this visualization, we quickly found 
that a line graph yielded a plot that was overwhelming and uncompelling. As such, 
we switched gears and decided to animate a scatterplot which allowed us to 
visualize the quartiles for both size and spending next to each other and see how 
these two things correlated to median park size and spending over the span of 
2012 and 2020. 


For the second graph... kathryn if you wanna hop in here and write out your approach

# add second graph approach

### Analysis

```{r question-1-vis-1}
### data wrangling
# to remove the $ and change from a categorical variable to a numerical variable 
# selected relevant variables, pivot wider to see what cities have data from every year
# drop na's from cities that do not have spending data from every year
# pivot longer to return dataset to a structure that can be plotted on a line plot

parks_q1 <- parks %>%
  select(year, city, spend_per_resident_data) %>% 
  mutate(across(starts_with("spend_per_resident_data"), ~gsub("\\$", "", .) 
                  %>% as.numeric)) %>% 
  pivot_wider(names_from = "year", 
              values_from = "spend_per_resident_data") %>% 
  drop_na() %>% #this is where we lose it 
  pivot_longer(cols = starts_with("20"),
               names_to = "year", 
               values_to = "spend_per_resident") 

#making the year variable numeric so we can join med_park_size_data back 
parks_q1 <- parks_q1 %>% 
  mutate(year = as.numeric(year))


#joining based on city and year to include med_park_size_data in the dataset
parks_q1 <- parks %>% 
  select(city, year, med_park_size_data) %>% 
  right_join(parks_q1, by = c("city","year")) 

fivenum(parks_q1$spend_per_resident)
#creating quartile bins for spending per resident, ranges based on five number summary
parks_q1 <- parks_q1 %>% 
  arrange(city) %>% 
  mutate(spending = case_when(
    between(spend_per_resident, 0, 62) ~ "1st quartile",
    between(spend_per_resident, 63, 94) ~ "2nd quartile",
    between(spend_per_resident, 95, 134) ~ "3rd quartile",
    TRUE ~ "4th quartile"
  ))

#creating quartile bins for median park size, ranges based on five number summary
  parks_q1 <- parks_q1 %>% 
    mutate(size = case_when(
    between(med_park_size_data, 0, 3.2) ~ "1st quartile",
    between(med_park_size_data, 3.21, 5.0) ~ "2nd quartile",
    between(med_park_size_data, 5.01, 7.7) ~ "3rd quartile",
    TRUE ~ "4th quartile"
  )) 

### plot of median park size vs spending per resident over time
  
q1_plot<- ggplot(parks_q1, aes(x = spend_per_resident, y = med_park_size_data, 
                               group = city)) + 
        geom_point(aes(size = size, color = spending)) +   
        labs(title = "Median Park Size vs. Spending Per Resident from 2012-2020 in 37 U.S. Cities",
             subtitle = "Year: {frame_time}",
             x = "Spending per Resident (USD)", 
             y = "Median Park Size (acres)", 
             size = "Park Size", 
             caption = "Quartiles for spending are $0-$62, $63-$94, $95-$134, and $135+ for 1st to 4th quartiles, respectively. 
Quartiles for size are 0-3.2 acres, 3.2-5.0 acres, 5.0-7.7 acres, 7.7+ acres for 1st to 4th quartiles respectively.",
             color = "Spending") +
        theme_minimal()+
        theme(plot.caption = element_text(size = 8, hjust = 0), 
              plot.title = element_text(size = 12), 
              legend.key.size = unit(.65, 'cm'), 
              legend.position = c(.9,.6)) +
        scale_x_continuous(breaks = seq(from = 0, to = 400, by = 50)) + 
        scale_y_continuous(breaks = seq(from = 0, to = 20, by = 5)) +
        scale_color_manual(values = c("#8999b0","#738148","#7c5d2d","#447aab")) +
        transition_time(as.integer(year), range = c(2012L, 2020L))

animate(q1_plot, duration = 18)
```

Links: 
https://github.com/thomasp85/gganimate/wiki/Animation-Composition
https://cran.r-project.org/web/packages/gganimate/gganimate.pdf
https://gganimate.com/
https://www.datanovia.com/en/blog/gganimate-how-to-create-plots-with-beautiful-animation-in-r/
http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html
https://ropensci.org/blog/2018/07/23/gifski-release/
https://gif.ski/
https://github.com/r-rust/gifski
https://gganimate.com/articles/gganimate.html#rendering-1
https://stackoverflow.com/questions/52899017/slow-down-gganimate-in-r

*note to self: what is the relationship between spending per resident and park size in different U.S. cities over time?*

```{question-2-vis-2}
### data wrangling

parks_regions <- parks_q1 %>% 
  mutate(region = case_when(
         city %in% c("Boston", "Long Beach", "New York", "Philadelphia") ~ "Northeast", 
         city %in% c("Atlanta", "Baltimore", "Jacksonville", "Louisville", 
                    "Memphis", "Nashville", "Virginia Beach") ~ "Southeast", 
         city %in% c("Chicago", "Columbus", "Detroit", "Kansas City", 
                     "Milwaukee") ~ "Midwest", 
         city %in% c("Albuquerque", "Austin", "Dallas", "El Paso", 
                     "Fort Worth", "Houston", "Mesa", "Oklahoma City",
                     "Phoenix", "San Antonio", "Tucson") ~ "Southwest", 
         city %in% c("Denver", "Fresno", "Las Vegas", "Los Angeles", 
                     "Portland", "Sacramento", "San Diego", "San Francisco", 
                     "San Jose", "Seattle") ~ "West"))

parks_regions <- parks_regions %>% 
  group_by(region, year) %>% 
  summarize(mean_spend = mean(spend_per_resident), mean_med_size = mean(med_park_size_data)) %>% 
  print()

### plot of mean spending per resident with respect to mean of median park size over time

ggplot(parks_regions, aes(x = year, y = mean_spend, group = region)) + 
  geom_line(aes(size = mean_med_size, color = region), lineend = "round") + 
  scale_color_manual(values = c("#738148", "#bc8a31", "#3b5c75", "#4f3e23", "#8999b0")) + 
    labs(title = "Mean Spending per Resident Over Time\n with Respect to Mean of Median Park Size", 
         subtitle = "by US Region",
         x = "Year", 
         y = "Mean Spending Per Resident (in USD)", 
         size = "Mean of Median Size (in acres)", 
         color = "Region")
```



### Discussion

(1-3 paragraphs)
In the Discussion section, interpret the results of your analysis. Identify any trends revealed (or not revealed) by the plots.
Speculate about why the data looks the way it does.

## How many amenities do parks with the top 10 and bottom 10 rankings in 2020 have and how does this vary based on what proportion of the top 10 and bottom 10 cities’ land is parkland in 2020?

### Introduction

For our second question, we wanted to look at parks with the top and bottom 10
rankings in 2020 and compare the percentage of their land being parkland. We 
also wanted to compare the number of amenities each of those parks have, 
including dog parks, playgrounds, restrooms, etc. To address these questions,
we merged the parks and cities datasets by city, and utilized the "city", 
"longitude", and "latitude" variables from the cities dataset, as well as the 
"rank" variable (to determine the top and bottom 10 park rankings) and variable 
for the amenities from the parks dataset. We thought this would be an 
interesting question to address as we wanted to illustrate and determine which 
variables were the most meaningful when determining the park rankings. We wanted
to compare and interpret whether the top 10 parks had much more amenities than 
the bottom 10 parks, and also visualize where those parks are geographically in
the US and how much of their cities' respective land is parkland.

### Approach

(1-2 paragraphs)
Describe what types of plots you are going to make to address your question.
For each plot, provide a clear explanation as to why this plot (e.g. boxplot, barplot, histogram, etc.) is best for providing the information you are asking about. 
The two plots should be of different types, and at least one of the two plots needs to use either color mapping or facets.



### Analysis

```{r question-2-vis-1}
### data wrangling

#top/bottom 10 cities
parks_2020 <- parks %>%
  filter(year == 2020,
         rank <= 10 | rank >= 88)

#matching cities dataframe with parks dataframe
cities <- cities %>%
  filter(state != "Maine") %>%
  mutate(city = case_when(city == "Washington" ~ "Washington, D.C.",
                          city == "Charlotte" ~ "Charlotte/Mecklenburg County",
                          TRUE ~ city)) %>%
  select(city, latitude, longitude) %>%
  rbind(tibble(city = c("Arlington, Virginia"),
               latitude = c(38.8816),
               longitude = c(-77.0910)))

#merging cities and parks data frames
parks_2020_coords <- left_join(parks_2020, cities, by = "city")

#creating an indicator variable for rank
parks_2020_coords <- parks_2020_coords %>%
  mutate(rank_div = ifelse(rank <= 10, "top", "bottom"))

#dodging overlapping points
parks_2020_coords <- parks_2020_coords %>%
  mutate(longitude = case_when(rank == 1 ~ -93.5,
                              rank == 3 ~ -92.6,
                              rank == 2 ~ -76.6,
                              rank == 4 ~ -77.5,
                              rank == 89 ~ -96.7,
                              rank == 94 ~ -97.5,
                              TRUE ~ longitude),
         updown = ifelse(rank %in% c(3, 89, 2), "down", "up"))

### plot of top/bottom 10 cities scaled by % of parkland

ggplot() +
  geom_polygon(data = map_data("state"), aes(x = long, y = lat, group = group),
               fill = "white", color = "gray60") +
  geom_point(data = parks_2020_coords,
             aes(x = longitude, y = latitude, color = rank_div,
                 size = as.numeric(str_extract(park_pct_city_data,"\\d+"))/100)) +
  geom_text(data = parks_2020_coords %>% filter(updown == "up"),
            aes(x = longitude, y = latitude, label = paste0("#",rank)),
            size = 3.5, vjust = -.8, family = "bold") +
  geom_text(data = parks_2020_coords %>% filter(updown == "down"),
            aes(x = longitude, y = latitude, label = paste0("#",rank)),
            size = 3.5, vjust = 1.8, family = "bold") +
  scale_size_continuous(labels = scales::percent) +
  scale_color_manual(values = c("#bc8a31", "#315d1b")) + 
  labs(x = NULL, y = NULL, size = "% of city that\nis parkland",
       title = "Top and bottom 10 city rankings of parks",
       subtitle = "scaled by % of city that is parkland") +
  coord_map() + 
  theme_void() +
  guides(color = "none") + 
  theme(legend.position = c(.92,.3),
        plot.title = element_text(hjust = 0.1),
        plot.subtitle = element_text(hjust = 0.1))
```

```{r question-2-vis-2, message = FALSE}
### data wrangling

#creating a total amenities variable
parks_2020_coords <- parks_2020_coords %>%
  mutate(total_amenities = playground_data + restroom_data + basketball_data)

#creating a long dataset for amenities
parks_amenities <- parks_2020_coords %>%
  pivot_longer(cols = c(playground_data, restroom_data, basketball_data), names_to = "amenity", values_to = "value") %>%
  mutate(city_n = paste0("#", rank, " ", city))

### plot of amenities 

ggplot(data = parks_amenities, mapping = aes(x = reorder(city_n, -rank))) + 
  geom_bar(stat = "identity", mapping = aes(y = value, fill = amenity)) +
  # geom_text(data = parks_2020_coords, mapping = aes(label = paste0("#",rank), y = total_amenities), hjust = -.1, 
  #           color = "black",
  #           family = "bold",
  #           size = 2.5) +
  coord_flip() +
  guides(fill = guide_legend(reverse = TRUE)) +
  labs(title = "Top and bottom 10 city rankings by amenities",
       y = "Total Amenities per 10K  Residents", x = NULL, fill = "Amenities") +
#       caption = "The number at the end of each bar represents the city's ranking") +
  scale_fill_manual(values = c("#bc8a31", "#738148", "#3b5c75"),
                    labels = c("Basketball Courts", "Playgrounds", "Restrooms")) + 
  theme(plot.title = element_text(hjust = 0),
        plot.subtitle = element_text(hjust = 0)) +
  theme_minimal()

#discarded code
#parks_2020_coords <- parks_2020_coords %>%
 # mutate(rank_quartile = case_when(rank <= 5 ~ "1st quartile",
  #                        rank > 5 & rank <= 10 ~ "2nd quartile",
   #                       rank >= 88 & rank < 93 ~ "3rd quartile",
    #                      rank >= 93 ~ "4th quartile"))

#ggplot(data = parks_amenities, mapping = aes(x = city, y = total_amenities, fill = total_amenities)) + 
  #geom_bar(stat = "identity") +
  #geom_text(data = parks_2020_coords, aes(label = rank), hjust = -.5, color = "black", family = "bold") +
  #coord_flip() +
  #labs(y = "Total Amenities", x = NULL)
```

(2-3 code blocks, 2 figures, text/code comments as needed)
In this section, provide the code that generates your plots. Use scale functions to provide nice axis labels and guides.
You are welcome to use theme functions to customize the appearance of your plot, but you are not required to do so.
All plots must be made with ggplot2. Do not use base R or lattice plotting functions.

### Discussion

(1-3 paragraphs)
In the Discussion section, interpret the results of your analysis. Identify any trends revealed (or not revealed) by the plots.
Speculate about why the data looks the way it does.

For the second question, our first visualization 

## Presentation

Our presentation can be found [here](presentation/presentation.html).

## Data 

Include a citation for your data here. 
See http://libraryguides.vu.edu.au/c.php?g=386501&p=4347840 for guidance on proper citation for datasets. 
If you got your data off the web, make sure to note the retrieval date.

## References

List any references here. You should, at a minimum, list your data source.